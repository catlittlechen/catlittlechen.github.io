<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[CatChen]]></title>
  <subtitle><![CDATA[我的王国，我一定会让你永垂不朽的]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://catlittlechen.com/"/>
  <updated>2019-11-16T07:05:43.581Z</updated>
  <id>http://catlittlechen.com/</id>
  
  <author>
    <name><![CDATA[Chan Cat]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[tmux]]></title>
    <link href="http://catlittlechen.com/2018/08/13/tmux/"/>
    <id>http://catlittlechen.com/2018/08/13/tmux/</id>
    <published>2018-08-13T05:57:03.000Z</published>
    <updated>2019-11-16T07:05:43.581Z</updated>
    <content type="html"><![CDATA[<h2 id="tmux"><a href="#tmux" class="headerlink" title="tmux"></a>tmux</h2><p>新的公司，开发需要远程到另外一台开发机器上，所以开始使用 tmux，虽然还是喜欢 ubuntu 的 terminal 多一些点。</p>
<h3 id="install"><a href="#install" class="headerlink" title="install"></a>install</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/tmux/tmux.git /tmp/tmux</span><br><span class="line">$ <span class="built_in">cd</span> /tmp/tmux</span><br><span class="line">$ git checkout 2.8</span><br><span class="line">$ sh autogen.sh</span><br><span class="line">$ ./configure &amp;&amp; make</span><br></pre></td></tr></table></figure>
<h3 id="conf"><a href="#conf" class="headerlink" title="conf"></a>conf</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span></span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/gpakosz/.tmux.git</span><br><span class="line">$ ln -s -f .tmux/.tmux.conf</span><br><span class="line">$ cp .tmux/.tmux.conf.local .</span><br></pre></td></tr></table></figure>
<h3 id="Bindings"><a href="#Bindings" class="headerlink" title="Bindings"></a>Bindings</h3><ul>
<li><p><code>&lt;prefix&gt;</code> 等价于 <code>ctrl + b</code> 或者 <code>ctrl + a</code></p>
</li>
<li><p>切屏</p>
<ul>
<li><code>&lt;prefix&gt; -</code> 水平切分 –&gt; tmux split</li>
<li><code>&lt;prefix&gt; _</code> 垂直切分 –&gt; tmux split -h</li>
</ul>
</li>
<li><p>切换</p>
<ul>
<li><code>&lt;prefix&gt; hjkl</code> 切换分部</li>
<li><code>&lt;prefix&gt; HJKL</code> 分部大小整理</li>
<li><code>&lt;prefix&gt; +</code> 将当前屏幕切分到另外一个窗口</li>
</ul>
</li>
<li><p>窗口</p>
<ul>
<li>tmux new-window</li>
<li><code>&lt;prefix&gt; ctrl h</code> 切换前一个窗口</li>
<li><code>&lt;prefix&gt; ctrl l</code> 切换后一个窗口</li>
<li><code>&lt;prefix&gt; number</code> 切换指定窗口</li>
<li><code>&lt;prefix&gt; w</code> 可以选择窗口哦</li>
<li>tmux rename-window $newName</li>
</ul>
</li>
</ul>
<h4 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">tmux new -s work</span></span><br><span class="line"><span class="meta">$</span><span class="bash"><span class="keyword">do</span> something</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&lt;prefix&gt; d</span></span><br><span class="line"><span class="meta">$</span><span class="bash">tmux a -s work</span></span><br></pre></td></tr></table></figure>]]></content>
    <summary type="html">
    <![CDATA[<h2 id="tmux"><a href="#tmux" class="headerlink" title="tmux"></a>tmux</h2><p>新的公司，开发需要远程到另外一台开发机器上，所以开始使用 tmux，虽然还是喜欢 ubuntu 的 terminal 多一些]]>
    </summary>
    
      <category term="工具" scheme="http://catlittlechen.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="学习" scheme="http://catlittlechen.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[向2017致敬]]></title>
    <link href="http://catlittlechen.com/2018/02/17/%E5%90%912017%E8%87%B4%E6%95%AC/"/>
    <id>http://catlittlechen.com/2018/02/17/向2017致敬/</id>
    <published>2018-02-16T16:38:52.000Z</published>
    <updated>2018-02-23T15:18:51.314Z</updated>
    <content type="html"><![CDATA[<h2 id="大概"><a href="#大概" class="headerlink" title="大概"></a>大概</h2><p>大年初一结束了。每年过年的放假，除了陪陪家人，次要的事情就是反思过去。</p>
<p>2017年，这个鸡年，打个分的话，只有59分，差一分及格。</p>
<p>也许，这是涅槃重生吧。为了不变成自己讨厌的人。为了听从自己心中最直白的话。</p>
<h2 id="家庭"><a href="#家庭" class="headerlink" title="家庭"></a>家庭</h2><p>对不起，爷爷。在日本跑了许久买回来的长寿符，我没能交到您的手中。听姐姐说，您走的时候，十分安详。从监控中，我看到您日渐消瘦，妈妈曾经暗示过我，但是我就是不相信。对不起，虽然靠着美林和消炎药，我才送了您人生的最后一程。而后的一个月，反复的发烧和咳嗽，一次又一次得提醒着我，这段悲伤的记忆。<br>对不起，老猫。我还记得第一次你来我家的时候，是10年前了。那时候你很害怕，一下子钻到沙发底下。从此，不愿意再走出这个家一步。妹妹说，你很懂事，知道也许爷爷去世后，我们就会去新家，而你不想去，就先离开了。爸爸并没有告诉我们出外的孩子，你什么时候离开的，依照习俗被放在了哪条河流里。回家后，没听到你的叫声，都不太习惯了。<br>对不起，妈妈。也许从小到大，我从来没让您失望过，也基本没有反驳过您。新家入宅后，您向我提出希望可以娶嘻嘻回家。而我拒绝了。也许不愿意我的人生再这样子按照世俗的轨迹去走，也许只是叛逆，也许为了自由人生，也许为了逃避责任吧。后来爸爸说您病了一场，十分惭愧。<br>对不起，爸爸。如果当初我做了最好的选择，那至少我现在有能力可以买下您现在的店铺。让您可以有个地方安心工作，即使喝喝茶也好。假以时日，我一定会买回来的。<br>对不起，妹妹。其实当初你接触微商的时候，我就想过，你会不会用到他们假的产品。但是我不知道后果会如此的严重。我后悔了。如果当初我阻止你，也不至于到了如今的地步。让你忍受了痛苦长达两年之久。你现在的痛苦，我有着大部分的责任。还好最近看到你在恢复，一切都会好的。<br>对不起，嘻嘻。我将毕业两年来的所有收入给了家里买房的时候，我很怕你离开我。可是你不但没有离开，还害怕我工作太累，不希望我去加班的公司。你给了我时间思考我的人生。可是我还是没能想到如何创造价值。你说我坚守的底线才错过那么多机会，但是也没强迫我做任何事。谢谢你。</p>
<h2 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h2><p>我从偶玩部门，去到国内广告，再借去海外部门，辗转最后到基础部门。这几年里面，基本上跑遍了整个公司所有部门。其实，公司性格测试的结果，我还是蛮认同的。我属于学者型的人，15蓝的典型理科生，喜欢学习新的事物，不喜欢重复劳动，洁癖一样的业务编码习惯。<br>小公司最好的地方，莫过于可以挑战很多新的技术，但是坏处也是需要短时间内拿出成果，不然很容易被否定。不过这也就是时代的需求。对于新的技术的从学习到应有，是需要快速交付的。只有在实践中，再慢慢探索，踩坑，填坑，最后从自己原有的架构里面，转化出新的架构。<br>不过，小公司不能好好地安心研究技术。因为大部分的小公司都是为了盈利而努力着。而技术大部分程度上都无法左右业务，所以结果上，福利会比大公司差很多。而以利润为基础的制度，感觉高层的错误决策，最终还是得下层的员工来承担。吧啦巴拉巴拉吧喇叭。<br>做了老板的同学和我说，工资和年终多少，大部分程度上并不是很所谓。但是一旦承诺了，而最终无论已任何理由少给或者不给，人心一下子就散了。不过为了所谓的什么什么，感觉公司的每个人都过得不容易。  </p>
<h2 id="自己"><a href="#自己" class="headerlink" title="自己"></a>自己</h2><p>2017年，有着很多误解、离别和伤痛。从挣扎，痛苦，沉默中慢慢重新看待这个世界。和大量的人接触，交换了人生的各种。2018开始了。<br>我明白这个世界不是付出了就可以有收获，但是只有付出，才能知道是否有收获。谢谢一直支持了这么年多的你们。对不起各位，我回来了。<br>在历史的长河里，自己像一个孤独无助的求学者。在喧嚣的路途中，静静地翻看着书籍。略去前人无数的重复的结论，探寻着世界自己无知的认知。不知道还可以好好看多久的书，多一页是一页吧。在阳光透过窗户时醒来，感受着温暖和生机，牢笼囚禁不住追求自由完美的心，愿拥有勇气面对多变的世界，愿拥有耐心面对不变的世界，愿拥有智慧去分辨两者，愿世界变得更加美好！！！</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="大概"><a href="#大概" class="headerlink" title="大概"></a>大概</h2><p>大年初一结束了。每年过年的放假，除了陪陪家人，次要的事情就是反思过去。</p>
<p>2017年，这个鸡年，打个分的话，只有59分，差一分及]]>
    </summary>
    
      <category term="生活" scheme="http://catlittlechen.com/tags/%E7%94%9F%E6%B4%BB/"/>
    
      <category term="活着" scheme="http://catlittlechen.com/categories/%E6%B4%BB%E7%9D%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[nginx_header]]></title>
    <link href="http://catlittlechen.com/2017/12/12/nginx-header/"/>
    <id>http://catlittlechen.com/2017/12/12/nginx-header/</id>
    <published>2017-12-12T11:36:56.000Z</published>
    <updated>2017-12-12T11:51:42.245Z</updated>
    <content type="html"><![CDATA[<h3 id="细节决定"><a href="#细节决定" class="headerlink" title="细节决定"></a>细节决定</h3><p>因为业务方的需求，需要在 nginx 那层做 ssl 等解析，然后将443端口过来的流量，proxy 到下层的80端口。业务层的机器上，同样也搭建了一个nginx，将流量根据 uri 分发到不同的服务上。</p>
<p>然后我犯错了。</p>
<p>在两层的 nginx 上，都有一个配置是 add_header <strong><strong>: </strong></strong>，所以放回的请求的 header 上，出现了两个相同 key 和相同 value 的 header。</p>
<p>所以当我用 curl 等命令请求数据的时候，可以完整的看到请求的 header 和 body。但是对于很多应用程序而言，这样子的 header 是非法的。</p>
<p>记得 http header 的问题之前也遇到过，golang在解析 header 的过程中，如果发现异常的时候，会直接放回40*，而不会有任何日志输出。当时还是新版本的特性，升级了golang版本后发版后，就让我开始怀疑人生。</p>
<p>总之，很多看起来不是很重要的细节，还是得了解。关键的时候，还是有用的。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="细节决定"><a href="#细节决定" class="headerlink" title="细节决定"></a>细节决定</h3><p>因为业务方的需求，需要在 nginx 那层做 ssl 等解析，然后将443端口过来的流量，proxy 到下层的80端口。业务]]>
    </summary>
    
      <category term="踩坑日记" scheme="http://catlittlechen.com/tags/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/"/>
    
      <category term="nginx" scheme="http://catlittlechen.com/tags/nginx/"/>
    
      <category term="踩坑日记" scheme="http://catlittlechen.com/categories/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[script]]></title>
    <link href="http://catlittlechen.com/2017/11/03/script/"/>
    <id>http://catlittlechen.com/2017/11/03/script/</id>
    <published>2017-11-03T11:34:36.000Z</published>
    <updated>2017-11-25T11:44:46.507Z</updated>
    <content type="html"><![CDATA[<p>写golang的时候，很多人都是用fmt来调试的。因此，大量的输出没出都要重定向到文件，然后查看，有时候挺烦的。其实有个命令，可以帮忙。那就是 script。</p>
<p>命令行中直接运行<code>script</code>命令后，它会默认将屏幕出现的所有内容，写入 typescript 的文件里面。<br>通过<code>exit</code>可以退出记录模式。<br>接下来就可以通过<code>more typescript</code>查看调试输出了.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>写golang的时候，很多人都是用fmt来调试的。因此，大量的输出没出都要重定向到文件，然后查看，有时候挺烦的。其实有个命令，可以帮忙。那就是 script。</p>
<p>命令行中直接运行<code>script</code>命令后，它会默认将屏幕出现的所有内容，写入 t]]>
    </summary>
    
      <category term="学习" scheme="http://catlittlechen.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="script" scheme="http://catlittlechen.com/tags/script/"/>
    
      <category term="学习" scheme="http://catlittlechen.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[kafka-replication]]></title>
    <link href="http://catlittlechen.com/2017/10/25/kafka-replication/"/>
    <id>http://catlittlechen.com/2017/10/25/kafka-replication/</id>
    <published>2017-10-25T06:23:03.000Z</published>
    <updated>2017-11-25T07:21:24.000Z</updated>
    <content type="html"><![CDATA[<h2 id="文章分享"><a href="#文章分享" class="headerlink" title="文章分享"></a>文章分享</h2><p><a href="https://www.confluent.io/blog/how-to-choose-the-number-of-topicspartitions-in-a-kafka-cluster/" target="_blank" rel="noopener">好文</a></p>
<p>这里讲述了 partition 对于并发的重要性，其中介绍了 kafka 实现中，kafka 处理每一个 partition 都是对应一个线程的，所以多 partition 之间是写入是可以并发的。读取的时候，多个 consumer 消耗对应的 partition 是可以增加吞吐量的。</p>
<p><a href="https://docs.confluent.io/current/kafka/deployment.html#hardware" target="_blank" rel="noopener">好文</a><br>这里讲述了 kafka 对硬件的选择。</p>
<h2 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h2><h3 id="add-broker"><a href="#add-broker" class="headerlink" title="add broker"></a>add broker</h3><p>kafka 加入一个 broker 只需要配置文件对了，直接起来就好了，没啥好说的。</p>
<h3 id="add-partitions"><a href="#add-partitions" class="headerlink" title="add partitions"></a>add partitions</h3><p>增加 partition 的话，通过<code>kafka-topics.sh</code>这个脚本即可。</p>
<pre><code>./kafka-topics.sh --alter --zookeeper 127.0.0.1:2181/kafka --partitions 10 --topic topic_test
</code></pre><h4 id="调整-partitions"><a href="#调整-partitions" class="headerlink" title="调整 partitions"></a>调整 partitions</h4><p>调整的话，是通过<code>kafka-reassign-partitions.sh</code>这个脚本提交任务的。具体教程网上蛮多的，还是多写一些吧。</p>
<h5 id="指定需要调整的-topics"><a href="#指定需要调整的-topics" class="headerlink" title="指定需要调整的 topics"></a>指定需要调整的 topics</h5><pre><code>{
      &quot;topics&quot;: [
        {&quot;topic&quot;:&quot;topic_test&quot;},
      ],
      &quot;version&quot;: 1
}
save to test.json
</code></pre><h5 id="生成调整后的-json"><a href="#生成调整后的-json" class="headerlink" title="生成调整后的 json"></a>生成调整后的 json</h5><pre><code>./kafka-reassign-partitions.sh --zookeeper 127.0.0.1:2181/kafka --topics-to-move-json-file ./test.json --broker-list &quot;0,1,2,3,4&quot; --generate
</code></pre><p>这里的 broker-list 是 kafka 配置文件里面 broker-id 的集合。<br>命令之后，会生成两个 json，一个是目前 partition 的分布，第二个是调整后的 partiton 分布，这里保存为 move.json。这里 kafka 是按照自己的算法生成的，实际上，并不是最优。所以最好对照目前 partition 的分布，自己再做调整。<br>原则有两个，1. Skewed, partition 分布要均匀；2. Leader Skewed, leader 分布要均匀。</p>
<h4 id="提交调整的-json"><a href="#提交调整的-json" class="headerlink" title="提交调整的 json"></a>提交调整的 json</h4><pre><code>./kafka-reassign-partitions.sh --zookeeper 127.0.0.1:2181/kafka --reassignment-json-file  move.json --execute
</code></pre><p>提交的任务是异步执行的，这个过程中网络磁盘IO都会很大，负载也会升高，所以需要注意。</p>
<h4 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h4><pre><code>./kafka-reassign-partitions.sh --zookeeper 127.0.0.1:2181/kafka --reassignment-json-file  move.json --verify
</code></pre><h3 id="指定-leader"><a href="#指定-leader" class="headerlink" title="指定 leader"></a>指定 leader</h3><p>指定 leader 的话，通过<code>kafka-preferred-replica-election.sh</code>这个脚本提交的。默认是选择了 Replicas 中，还出于 sycn 状态的broker的第一个。所以上面提交调整的 json，需要把这一条考虑进去，注意 broker 的顺序。</p>
<pre><code>./kafka-preferred-replica-election.sh --zookeeper 127.0.0.1:2181/kafka
</code></pre>]]></content>
    <summary type="html">
    <![CDATA[<h2 id="文章分享"><a href="#文章分享" class="headerlink" title="文章分享"></a>文章分享</h2><p><a href="https://www.confluent.io/blog/how-to-choose-the-numbe]]>
    </summary>
    
      <category term="学习" scheme="http://catlittlechen.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="kafka" scheme="http://catlittlechen.com/tags/kafka/"/>
    
      <category term="kafka" scheme="http://catlittlechen.com/categories/kafka/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[kafka]]></title>
    <link href="http://catlittlechen.com/2017/10/10/kafka/"/>
    <id>http://catlittlechen.com/2017/10/10/kafka/</id>
    <published>2017-10-10T14:54:53.000Z</published>
    <updated>2017-11-25T06:23:38.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><p>一大利器，以零拷贝，文件append之类好玩的优点，而被选择为了很多公司的数据总线，配置什么的就不多说了，Google等搜索引擎可以找到很多文章来介绍，那我就介绍下，我遇到的问题吧。</p>
<h2 id="formatVersion"><a href="#formatVersion" class="headerlink" title="formatVersion"></a>formatVersion</h2><p>  kafka从0.8版本到现在，message的format有了3个版本，其中v1，v2的差距不大，但是v3的版本为了batch而生，因而版本差异比较大。<br>  但是落地到文件的版本，是由kafka启动的配置文件中配置的。kafka为了兼容各个版本，在通讯协议中支持message版本之间的转化。但是这个转化势必在server端执行，会浪费不必要的CPU，因为，在使用kafka的过程中，最好是根据业务需要，统一server与client的messageFormatVersion。</p>
<h2 id="jmxtrans"><a href="#jmxtrans" class="headerlink" title="jmxtrans"></a>jmxtrans</h2><p>  kafka原生会暴露一个java系的监控接口，在kafka-server-start.sh中，可以看到JMX_PORT相关的配置。而jmxtrans是一个服务，可以将kafka—jmx中暴露出来的数据，整理写入ganglia中。配置可以看它的<a href="https://github.com/jmxtrans/jmxtrans" target="_blank" rel="noopener">github</a>，kafka的监控项可以看<a href="http://kafka.apache.org/documentation/#configuration" target="_blank" rel="noopener">官网</a></p>
<h2 id="kafka-manager"><a href="#kafka-manager" class="headerlink" title="kafka-manager"></a>kafka-manager</h2><p>  好吧，业务的同学都是喜欢有个页面的监控，所以嘛，找个yahoo的这个<a href="https://github.com/yahoo/kafka-manager" target="_blank" rel="noopener">监控</a>.配置简单，可以通过jmx的接口，查找到类似于consumerGroup的延迟，数据传输的监控，并且可以看到类似于out of Sync等。点到为止~</p>
<h2 id="replications"><a href="#replications" class="headerlink" title="replications"></a>replications</h2><p>  一个好的作品都是留给了使用者很多配置，很多很多配置。因此，kafka留了这个replication特性。如果你只关注性能，那么replication=1，每一个partition只有一份，这个在写入的时候，性能最佳，坏处就是单一个kafka实例失败的时候，这个partition就失败了。但是，一旦设置了replication&gt;1，那么kafka实例失败后，这个实例的partition只是outOfSync，重启等操作后，可以恢复。整个集群的partition还是可用的。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><p>一大利器，以零拷贝，文件append之类好玩的优点，而被选择为了很多公司的数据总线，配置什么的就不多说了，Googl]]>
    </summary>
    
      <category term="学习" scheme="http://catlittlechen.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="kafka" scheme="http://catlittlechen.com/tags/kafka/"/>
    
      <category term="kafka" scheme="http://catlittlechen.com/categories/kafka/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[whoiam]]></title>
    <link href="http://catlittlechen.com/2017/09/24/whoiam/"/>
    <id>http://catlittlechen.com/2017/09/24/whoiam/</id>
    <published>2017-09-23T16:18:44.000Z</published>
    <updated>2017-09-23T17:33:47.000Z</updated>
    <content type="html"><![CDATA[<p>你离开的第一周，生活继续。</p>
<p>我在手机的备忘录里面，记录了我自问的所有问题。只是我找不到答案。</p>
<p>最近发生了很多事情，我该记一记。</p>
<ol>
<li>这周刚好飞哥他们参加各种校招笔试面试，所以下班后也帮他们做做笔试，讲解各种遇到的知识点。但是只是他们临时抱佛脚而已，被问多了，自然露马脚。总觉得这么做不对，但是我也只能帮一些了。之前明明很多次提醒他们该做什么，似乎也没什么用。这是个人性格问题吧。毕竟肯好好看书的人，实在不多了。</li>
<li>我发现，身边好多擦边球的赚钱玩法，发现聚会的时候，都开始聊起这样子的话题。可我还是不喜欢，甚至难受。我在我可预见的未来里面，虽然看到了悲观的可能性，但是走一步看一步吧。我总觉得毕业了两年，还像一个学生。也许这也挺好的。可以脚踏实地，仰望星空的生活，是我这么多年，最大的欣慰了吧。我只是不想，活成我讨厌的那种人。</li>
<li>我在国内的那段时间内，我在想，我和叶同学，黄同学之间的区别。技术在我看来，是一种知识，需要不断尝试掌握的。他们身上，我和我很像的求知欲。但是黄同学毕竟是管理层，所以也在乎KPI，但是他的能力不容置疑。叶同学，人很nick，足够的亲和度，可以融洽整个团队。写了这个多，感觉我缺少的是决断的能力。干了这么多年，惭愧了。破而不立，是目前一个瓶颈，我知道什么场景适用什么技术架构，但是需要新的场景，我可以很快地否定不好的方案。但是自己却没办法提出更好的，甚至于完美的方案。</li>
<li>时间到底怎么了。公司一直在成长，也许大家习惯了围绕着业务开展，工作时间被迫碎片化。以为做了很多东西，实际上并没有做出什么成就。</li>
<li>回头看了上面写的东西，有点想删除的冲动。今天公司举办运动会，一开始我是拒绝的。实际上我差点拒绝了。虽然最后还是去了，还参加了拔河比赛。亚军也挺不错的啦。fate/zero里面征服者大帝曾经说过，一个人的不该为了别人的梦想而努力，而应该寻找这一群有相同梦想的人，然后去完成这个梦想。这是很多人渴望有团队活动的原因。</li>
<li>困了，睡觉吧~</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<p>你离开的第一周，生活继续。</p>
<p>我在手机的备忘录里面，记录了我自问的所有问题。只是我找不到答案。</p>
<p>最近发生了很多事情，我该记一记。</p>
<ol>
<li>这周刚好飞哥他们参加各种校招笔试面试，所以下班后也帮他们做做笔试，讲解各种遇到的知识点。但是]]>
    </summary>
    
      <category term="生活" scheme="http://catlittlechen.com/tags/%E7%94%9F%E6%B4%BB/"/>
    
      <category term="转折" scheme="http://catlittlechen.com/tags/%E8%BD%AC%E6%8A%98/"/>
    
      <category term="活着" scheme="http://catlittlechen.com/categories/%E6%B4%BB%E7%9D%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[oneproxy]]></title>
    <link href="http://catlittlechen.com/2017/09/21/oneproxy/"/>
    <id>http://catlittlechen.com/2017/09/21/oneproxy/</id>
    <published>2017-09-21T00:49:25.000Z</published>
    <updated>2017-09-26T13:57:21.000Z</updated>
    <content type="html"><![CDATA[<p>前段时间调研了一下oneproxy，google收录的资料比较少，基本都是看得官方的博客文章．<br><a href="http://www.onexsoft.com" target="_blank" rel="noopener">oneproxy</a>，出生于阿里系的人员之手，主要的目的是为了解决数据库变迁所带来的问题．</p>
<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>负载均衡 + 分库分表 + 大数据 + SQL监控 + 安全审计</p>
<p>说说我想了解的几个方面吧～</p>
<h2 id="SQL监控"><a href="#SQL监控" class="headerlink" title="SQL监控"></a>SQL监控</h2><p>在解决安全方面，oneproxy有几个层次验证拦截．<br>  1．网络隔离，oneproxy可以限制其他机器对端口的访问</p>
<ol>
<li>登录验证，就是数据库用户密码验证</li>
<li>访问限制，就是MySQL等常见的权限验证</li>
<li>应用验证，类似于Google的动态口令，发送一个特殊的SQL语句来对数据库的访问进行解锁</li>
<li>SQL白名单，需要搜集目前可以执行的SQL模板形成白名单，可以有效的防止SQL注入．<br>除此之外，还有基于客户端IP地址的流量控制，而且还有很多监控相关的数据可以查看，具体就不罗列了．</li>
</ol>
<h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>由于oneproxy实际上是一个代理，所以实际上，后端到底是访问哪个数据库，对于用户本身是未知的．<br>如同haproxy或者codis这一类应用一样，它可以减少实际数据库的链接数，减少tcp链接频繁创建．<br>所以，oneproxy不能用<code>use</code>,存储过程，<code>prepare</code>这一类的操作．<br>更大的好处是，多实例数据库可以防止单点故障．</p>
<p>我看oneproxy有相关的配置，可以让它优先去访问master还是slave数据库，但是这个操作是oneproxy实例级别的，大部分业务场景都是读写分离，但是对于部分实时性要求比较高的场景，读写都会在主数据库完成，即使是开了SemiSync也是不够的，是否可以做到指定呢？还是说，这时候实际上，开发不应该基于MySQL等来完成实时的一致性校验．<br>目前的策略是 read_slave, read_balance, big_slave, big_balance．完整的介绍<a href="http://www.onexsoft.com/zh/oneproxy-read-traffic-scaleout.html" target="_blank" rel="noopener">传送门</a></p>
<h2 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h2><p>这是很多proxy都需要支持的一个特性，mysql实际上也是支持单实例的分区的，不过这对SQL解析和merge数据方存在一定的挑战．这个特性的基础上，大表可以根据需要分散到各个不同的数据库实例之中，对查询的性能瓶颈有很大的突破．不过存在的问题，比如分布式事务的支持，我看oneproxy还是没有解决的，毕竟老大难．<br>这里有个很不错的功能，是在分库分表的情况下，可以生成对应的主键．<a href="http://www.onexsoft.com/zh/oneproxy-sharding-key-sequence.html" target="_blank" rel="noopener">创送们</a> 从前自己实现的分表里面，主键是通过redis来维护的自增值．用oneproxy的话，就方便多了～</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>前段时间调研了一下oneproxy，google收录的资料比较少，基本都是看得官方的博客文章．<br><a href="http://www.onexsoft.com" target="_blank" rel="noopener">oneproxy</a>，出生于阿里系的人]]>
    </summary>
    
      <category term="学习" scheme="http://catlittlechen.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="oneproxy" scheme="http://catlittlechen.com/tags/oneproxy/"/>
    
      <category term="学习" scheme="http://catlittlechen.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[naxsi]]></title>
    <link href="http://catlittlechen.com/2017/09/16/naxsi/"/>
    <id>http://catlittlechen.com/2017/09/16/naxsi/</id>
    <published>2017-09-16T12:58:16.000Z</published>
    <updated>2017-09-26T13:56:08.000Z</updated>
    <content type="html"><![CDATA[<h2 id="Naxsi"><a href="#Naxsi" class="headerlink" title="Naxsi"></a><a href="https://github.com/nbs-system/naxsi" target="_blank" rel="noopener">Naxsi</a></h2><p>github上，NAXSI自我介绍是Nginx Anti XSS &amp; SQL Injection。顾名思义，他是nginx一个用来防止XSS和SQL注入的Nginx插件。</p>
<p>原来就是将请求的各个参数，通过Naxsi预先设置的规则判断，通过得分，来决定是否拦截。</p>
<h3 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h3><p>安装很简单，ubuntu上面只需要<code>apt-get nginx-naxsi</code>就可以啦~其他系统则可以选择官方介绍的，将Naxsi编译进nginx中，wiki上注明需要优先编译Naxsi。</p>
<h3 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h3><ol>
<li>在http{}层，加入<code>include naxsi_core.rules</code>。naxsi_core.rules是naxsi自带的核心规则。可以防止一般的SQL注入和XSS。</li>
<li>在server{}层，可以动态的设定一些参数。具体见<a href="https://github.com/nbs-system/naxsi/wiki/runtime-modifiers" target="_blank" rel="noopener">传送门</a>。</li>
<li>在location{}层，可以设置naxsi的开关(是否执行，学习模式[–&gt;观察者模式])，白名单，拦截规则，还有拦截后的重定向。依旧是一个[传送门] (<a href="https://github.com/nbs-system/naxsi/wiki/naxsi-setup)。" target="_blank" rel="noopener">https://github.com/nbs-system/naxsi/wiki/naxsi-setup)。</a></li>
</ol>
<h3 id="具体细节"><a href="#具体细节" class="headerlink" title="具体细节"></a>具体细节</h3><p>LearningMode是学习模式，开启后，naxsi会在errorLog中打出拦截的请求和拦截的原因，但是并不会真正的拦截请求。因此，使用者可以通过errLog分析得到目前的拦截规则是否适用于服务。</p>
<p>errLog大概长得像这样子</p>
<pre><code>2017/09/15 06:12:33 [error] 18321#0: *291887486 NAXSI_FMT: ip=172.16.1.1&amp;server=a.b.com&amp;uri=/hello&amp;learning=1&amp;vers=0.55.3&amp;total_processed=10086&amp;total_blocked=404&amp;block=1&amp;cscore0=$SQL&amp;score0=8&amp;zone0=ARGS&amp;id0=1000&amp;var_name0=s&amp;zone1=ARGS&amp;id1=1009&amp;var_name1=s, client: 172.16.1.1, server: a.b.com, request: &quot;GET /hello?s=***** HTTP/1.1&quot;, host: &quot;a.b.com&quot;
</code></pre><p>Naxsi认为，请求参数里面s中，有可能存在SQL注入(csore0=$SQL)，并且告诉我们，参与判定的规则是1000(id0=1000)，有问题的参数是s(var_name0=s)，当然出问题的不仅仅是一处时，他将会以平铺的模式，继续追加结果，如上所示。</p>
<p>如果我们认为，这个参数是不存在问题的，可以自己加入白名单。<br>比如如果我们想要将s这个参数排除在检测之外，则可以加入如下规则：</p>
<pre><code>BasicRule wl:0 &quot;mz:$ARGS_VAR:s|$URL:/hello&quot;;
</code></pre><h2 id="Nxapi"><a href="#Nxapi" class="headerlink" title="Nxapi"></a>Nxapi</h2><p>对于大型网站而言，一旦开启了Naxsi，产生的errLog将会极其庞大。Naxsi提供一个方案，来做事件分析，生成相应的白名单。这就是<a href="https://github.com/nbs-system/naxsi/tree/master/nxapi" target="_blank" rel="noopener">nxapi</a>啦。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Naxsi"><a href="#Naxsi" class="headerlink" title="Naxsi"></a><a href="https://github.com/nbs-system/naxsi" target="_blank" rel="noop]]>
    </summary>
    
      <category term="学习" scheme="http://catlittlechen.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="naxsi" scheme="http://catlittlechen.com/tags/naxsi/"/>
    
      <category term="学习" scheme="http://catlittlechen.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[踩坑日记之Upstart]]></title>
    <link href="http://catlittlechen.com/2017/08/11/upstart/"/>
    <id>http://catlittlechen.com/2017/08/11/upstart/</id>
    <published>2017-08-11T15:03:55.000Z</published>
    <updated>2017-09-26T13:57:36.000Z</updated>
    <content type="html"><![CDATA[<h4 id="Upstart的Expect"><a href="#Upstart的Expect" class="headerlink" title="Upstart的Expect"></a>Upstart的Expect</h4><p>用upstart来管理系统的服务，很常见。但是也有需要注意的地方。比如，配置文件里面的expect。</p>
<p>Expect有两种，”expect fork”表示进程只会fork一次，”expect daemonize”表示进程会fork两次，将自己变成后台进程。</p>
<p>然而，错误的配置文件会让upstart启动某个进程之后，却无法跟踪管理这个进程的PID。结果Upstart会进入奇妙的状态。</p>
<p>没办法，虽然本应该是它的PID，还没找到就不见了~因此，它十分怀念，念念不忘这个PID，以至于再也无法控制这个程序~无法启动，停止，重启这个进程。</p>
<h3 id="怎么办？"><a href="#怎么办？" class="headerlink" title="怎么办？"></a>怎么办？</h3><p>方法其实很简单，如果我们可以启动一个服务，它的PID是Upstart所需要的PID，然后让Upstart跟踪到，然后kill掉这个PID的进程，那么Upstart的行为才可以变为正常。</p>
<h3 id="code"><a href="#code" class="headerlink" title="code"></a>code</h3><p>有一个ruby的<a href="https://raw.githubusercontent.com/ion1/workaround-upstart-snafu/master/workaround-upstart-snafu" target="_blank" rel="noopener">代码</a>，可以参考下。亲测可用~</p>
]]></content>
    <summary type="html">
    <![CDATA[<h4 id="Upstart的Expect"><a href="#Upstart的Expect" class="headerlink" title="Upstart的Expect"></a>Upstart的Expect</h4><p>用upstart来管理系统的服务，很常见。但]]>
    </summary>
    
      <category term="踩坑日记" scheme="http://catlittlechen.com/tags/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/"/>
    
      <category term="upstart" scheme="http://catlittlechen.com/tags/upstart/"/>
    
      <category term="踩坑日记" scheme="http://catlittlechen.com/categories/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[踩坑日记之nginx-limit-req]]></title>
    <link href="http://catlittlechen.com/2017/08/10/nginx/"/>
    <id>http://catlittlechen.com/2017/08/10/nginx/</id>
    <published>2017-08-10T15:47:11.000Z</published>
    <updated>2017-09-26T13:56:59.000Z</updated>
    <content type="html"><![CDATA[<p>一般我们都认为nginx -t可以测试出配置文件是否配置正确。<br>其实不然~</p>
<h4 id="limit-req-zone"><a href="#limit-req-zone" class="headerlink" title="limit_req_zone"></a><code>limit_req_zone</code></h4><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">limit_req_zone  <span class="variable">$binary_remote_addr</span>  <span class="attribute">zone</span>=req_one:10m <span class="attribute">rate</span>=1r/s</span><br></pre></td></tr></table></figure>
<p>这是nginx配置速率限制的插件。具体可以自行查询相关资料。</p>
<h4 id="坑"><a href="#坑" class="headerlink" title="坑"></a>坑</h4><p>当时原本设置的限制条件为$uri，测试的过程中，发现实际上$request_uri才是符合要求的限制条件，因而修改了配置，<code>nginx -t</code>测试顺利通过，<code>nginx -s reload</code>也没有任何报错。但是实际上，nginx worker并没有退出。</p>
<p>一开始还认为是worker承载的请求太多，以至于请求没能处理完毕，导师worker延迟退出。<br>直到多心去看了一眼日志，才发现，limit_req这个模块，在设置<code>limit_req_zone</code>的时候是无法修改限制条件的。</p>
<h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><p>只能够同时修改zone~~~</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>一般我们都认为nginx -t可以测试出配置文件是否配置正确。<br>其实不然~</p>
<h4 id="limit-req-zone"><a href="#limit-req-zone" class="headerlink" title="limit_req_zone">]]>
    </summary>
    
      <category term="踩坑日记" scheme="http://catlittlechen.com/tags/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/"/>
    
      <category term="nginx" scheme="http://catlittlechen.com/tags/nginx/"/>
    
      <category term="踩坑日记" scheme="http://catlittlechen.com/categories/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[pyrobuf的改进]]></title>
    <link href="http://catlittlechen.com/2017/07/12/pyrobuf%E7%9A%84%E6%94%B9%E8%BF%9B/"/>
    <id>http://catlittlechen.com/2017/07/12/pyrobuf的改进/</id>
    <published>2017-07-12T02:42:18.000Z</published>
    <updated>2017-09-02T03:11:03.000Z</updated>
    <content type="html"><![CDATA[<h3 id="问题-1-–字符串编码"><a href="#问题-1-–字符串编码" class="headerlink" title="问题(1)–字符串编码"></a>问题(1)–字符串编码</h3><p>protobuf的标准里面，所有的字符串都是标准的UTF-8模式。而python恰恰是一个经常性遇到字符串编码问题的语言。</p>
<p>但是pyrobuf里面，处理字符串的时候，当遇到字符串问题的时候，不会跑出错误，而会直接崩溃。</p>
<h3 id="解决-1"><a href="#解决-1" class="headerlink" title="解决(1)"></a>解决(1)</h3><p>源码的模板中，可以选择在字符串decode的判断中，加入try-except，pass掉错误。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">	self._ = unicode(memory[current_offset:current_offset + field_size], <span class="string">'utf-8'</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">	self._ = <span class="string">u''</span></span><br><span class="line">	<span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>当然，这种修改必须修改掉全部的decode判断。也有另外一种方式，就是简单地抛出错误。</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cdef <span class="keyword">int</span> _protobuf_deserialize(self, <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">char</span> *memory, <span class="keyword">int</span> <span class="built_in">size</span>) except <span class="number">-1</span>:</span><br></pre></td></tr></table></figure>
<p>在cython中<code>except -1</code>,代表着会将抛出的错误转化为python里面的Exception，就可以被上层调用的代码捕捉，不至于直接退出程序。</p>
<h3 id="问题-2-–字段缺少"><a href="#问题-2-–字段缺少" class="headerlink" title="问题(2)–字段缺少"></a>问题(2)–字段缺少</h3><p>通过源码阅读，可以发现实际上如果protobuf里面的字段我并不需要，那么精简proto定义，可以减少解析的字段，因而优化解析的性能。然而，pyrobuf却判断了传入的data的长度，和解析过的长度，然后抛出了错误，</p>
<h3 id="解决-2"><a href="#解决-2" class="headerlink" title="解决(2)"></a>解决(2)</h3><p>因而，需要删除这部分判断。<br><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> buf != <span class="keyword">length</span>:</span><br><span class="line">	raise DecodeError(<span class="string">"Truncated message: got %s expected %s"</span> % (buf, size))</span><br></pre></td></tr></table></figure></p>
<h2 id="另辟溪路"><a href="#另辟溪路" class="headerlink" title="另辟溪路"></a>另辟溪路</h2><p>google的protobuf库里面实际上已经有了protobufc，解析的效率实际上与pyrobuf差不多。如果单纯只是解析的话，可以直接使用google的原生库。当然，pyrobuf还提供了输出到json,dict的函数~~</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="问题-1-–字符串编码"><a href="#问题-1-–字符串编码" class="headerlink" title="问题(1)–字符串编码"></a>问题(1)–字符串编码</h3><p>protobuf的标准里面，所有的字符串都是标准的UTF-8模式。而]]>
    </summary>
    
      <category term="python" scheme="http://catlittlechen.com/tags/python/"/>
    
      <category term="pyrobuf" scheme="http://catlittlechen.com/tags/pyrobuf/"/>
    
      <category term="python" scheme="http://catlittlechen.com/categories/python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[ganglia-buffer]]></title>
    <link href="http://catlittlechen.com/2017/07/10/ganglia-buffer/"/>
    <id>http://catlittlechen.com/2017/07/10/ganglia-buffer/</id>
    <published>2017-07-10T11:03:58.000Z</published>
    <updated>2017-09-26T13:58:30.000Z</updated>
    <content type="html"><![CDATA[<p>最近给服务器的redis-cluster加ganglia监控，但是配置加载之后，ganglia却失控了．面板上面ganglia部分数据无法显示．debug的时候，发现ganglia-monitor可以正常的收集数据，那么问题出在哪里呢？</p>
<h2 id="etc-ganglia-gmond-conf"><a href="#etc-ganglia-gmond-conf" class="headerlink" title="/etc/ganglia/gmond.conf"></a>/etc/ganglia/gmond.conf</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">udp_recv_channel &#123;</span><br><span class="line">   <span class="built_in"> port </span>= 8649</span><br><span class="line">    bind = ***.***.***.***</span><br><span class="line">    retry_bind = <span class="literal">true</span></span><br><span class="line">    # Size of the UDP buffer. <span class="keyword">If</span> you are handling lots of metrics you really # should bump it up <span class="keyword">to</span> e.g. 10MB <span class="keyword">or</span> even higher.</span><br><span class="line">    buffer = 10485760</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>gmond默认的配置文件里面并没有写上这行配置，所以很多人都会忽略掉．</p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>修改buffer大小就可以啦．</p>
<h2 id="Done"><a href="#Done" class="headerlink" title="Done"></a>Done</h2>]]></content>
    <summary type="html">
    <![CDATA[<p>最近给服务器的redis-cluster加ganglia监控，但是配置加载之后，ganglia却失控了．面板上面ganglia部分数据无法显示．debug的时候，发现ganglia-monitor可以正常的收集数据，那么问题出在哪里呢？</p>
<h2 id="etc-ga]]>
    </summary>
    
      <category term="踩坑日记" scheme="http://catlittlechen.com/tags/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/"/>
    
      <category term="ganglia" scheme="http://catlittlechen.com/tags/ganglia/"/>
    
      <category term="踩坑日记" scheme="http://catlittlechen.com/categories/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[那些年不懂的spark(4)]]></title>
    <link href="http://catlittlechen.com/2017/07/01/%E9%82%A3%E4%BA%9B%E5%B9%B4%E4%B8%8D%E6%87%82%E7%9A%84spark-4/"/>
    <id>http://catlittlechen.com/2017/07/01/那些年不懂的spark-4/</id>
    <published>2017-07-01T03:19:20.000Z</published>
    <updated>2017-09-02T03:14:45.000Z</updated>
    <content type="html"><![CDATA[<h2 id="spark-files"><a href="#spark-files" class="headerlink" title="spark-files"></a>spark-files</h2><p>spark-default.xml<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark<span class="selector-class">.files</span><span class="selector-class">.maxPartitionBytes</span> <span class="number">67108864</span></span><br><span class="line">spark<span class="selector-class">.sql</span><span class="selector-class">.files</span><span class="selector-class">.maxPartitionBytes</span> <span class="number">33554432</span></span><br></pre></td></tr></table></figure></p>
<p>spark在读取大文件的时候会自动的分区，这时候分区的标准就是上面这两个参数．<br>因此可以根据这两个参数调配任务的task，防止内存爆了．</p>
<h2 id="spark-dynamicAllocation"><a href="#spark-dynamicAllocation" class="headerlink" title="spark-dynamicAllocation"></a>spark-dynamicAllocation</h2><p>spark-default.xml<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark<span class="selector-class">.dynamicAllocation</span><span class="selector-class">.enabled</span>  true</span><br><span class="line">spark<span class="selector-class">.dynamicAllocation</span><span class="selector-class">.executorIdleTimeout</span> <span class="number">10s</span></span><br></pre></td></tr></table></figure></p>
<p>dynamicAllocation 是spark自动调配executor的方式．可以尽可能的使用spark集群，<br>调节executorIdleTimeout，可以在任务使用完executor之后，尽快地释放executor，使得其它任务可以尽快的使用．</p>
<h2 id="结局"><a href="#结局" class="headerlink" title="结局"></a>结局</h2><p>未完待续</p>
<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>偶尔会遇到timeout的情况，这时候一般都是内存不足，一直不是很明白spark到底怎么使用内存的．也许不是java党的缘故，有点难以着手．有空再好好剖析．</p>
<h2 id="Done"><a href="#Done" class="headerlink" title="Done"></a>Done</h2>]]></content>
    <summary type="html">
    <![CDATA[<h2 id="spark-files"><a href="#spark-files" class="headerlink" title="spark-files"></a>spark-files</h2><p>spark-default.xml<br><figure class]]>
    </summary>
    
      <category term="踩坑日记" scheme="http://catlittlechen.com/tags/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/"/>
    
      <category term="spark" scheme="http://catlittlechen.com/tags/spark/"/>
    
      <category term="spark" scheme="http://catlittlechen.com/categories/spark/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[那些年不懂的spark(3)]]></title>
    <link href="http://catlittlechen.com/2017/06/03/%E9%82%A3%E4%BA%9B%E5%B9%B4%E4%B8%8D%E6%87%82%E7%9A%84spark-3/"/>
    <id>http://catlittlechen.com/2017/06/03/那些年不懂的spark-3/</id>
    <published>2017-06-03T04:13:45.000Z</published>
    <updated>2017-06-03T06:34:46.000Z</updated>
    <content type="html"><![CDATA[<p>aws的emr起来之后，默认的磁盘很小，所以长期跑任务的时候，经常会因为磁盘不够，导致节点失败。而且，这种情况下的emr，是不会自动修复的。</p>
<h2 id="spark-history"><a href="#spark-history" class="headerlink" title="spark-history"></a>spark-history</h2><p>spark-default.xml<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spark<span class="selector-class">.history</span><span class="selector-class">.fs</span><span class="selector-class">.cleaner</span><span class="selector-class">.enabled</span> true</span><br><span class="line">spark<span class="selector-class">.history</span><span class="selector-class">.fs</span><span class="selector-class">.cleaner</span><span class="selector-class">.interval</span> <span class="number">1</span>m</span><br><span class="line">spark<span class="selector-class">.history</span><span class="selector-class">.fs</span><span class="selector-class">.cleaner</span><span class="selector-class">.maxAge</span> <span class="number">1</span>h</span><br></pre></td></tr></table></figure></p>
<p>spark-history里面保存着spark的application的log，因此如果不需要的话，可以把清理的时间变短一下。</p>
<h2 id="spark-yarn"><a href="#spark-yarn" class="headerlink" title="spark-yarn"></a>spark-yarn</h2><p>yarn-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.localizer.cache.target-size-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>5120<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.localizer.cache.cleanup.interval-ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>30000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>spark执行任务的时候，会将自身需要的jar放到hadoop上，导致hadoop的磁盘会缓存下一堆的目录，也是可以定期清理的。</p>
<h2 id="结局"><a href="#结局" class="headerlink" title="结局"></a>结局</h2><p>未完待续</p>
<h2 id="Done"><a href="#Done" class="headerlink" title="Done"></a>Done</h2>]]></content>
    <summary type="html">
    <![CDATA[<p>aws的emr起来之后，默认的磁盘很小，所以长期跑任务的时候，经常会因为磁盘不够，导致节点失败。而且，这种情况下的emr，是不会自动修复的。</p>
<h2 id="spark-history"><a href="#spark-history" class="headerl]]>
    </summary>
    
      <category term="踩坑日记" scheme="http://catlittlechen.com/tags/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/"/>
    
      <category term="spark" scheme="http://catlittlechen.com/tags/spark/"/>
    
      <category term="spark" scheme="http://catlittlechen.com/categories/spark/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[touch]]></title>
    <link href="http://catlittlechen.com/2017/05/26/touch/"/>
    <id>http://catlittlechen.com/2017/05/26/touch/</id>
    <published>2017-05-26T07:26:01.000Z</published>
    <updated>2017-05-26T07:45:29.000Z</updated>
    <content type="html"><![CDATA[<h3 id="Touch"><a href="#Touch" class="headerlink" title="Touch"></a>Touch</h3><p>touch这个命令,对于一个技术而言,应该是十分熟悉的.<br>像uwsgi这种就可以使用监听一个文件的方式来触发服务更新的部署方式,我们这时候就会用到<code>touch reload</code>的命令来完成.<br>更重要的是,我习惯性地打<code>ls -al</code>的命令来查看文件的最后修改时间,来查看是否有小朋友乱动了线上的文件.</p>
<p>直到有一天……..<br>有同事告诉我,touch有个神奇的功能.<br>于是乎,我<code>touch --help</code>下</p>
<pre><code>-a            只更改访问时间
-c, --no-create 不创建任何文件
-d, --date=字符串 使用指定字符串表示时间而非当前时间
-f          (忽略)
-h, --no-dereference      会影响符号链接本身，而非符号链接所指示的目的地
    (当系统支持更改符号链接的所有者时，此选项才有用)
-m            只更改修改时间
-r, --reference=FILE   use this file&apos;s times instead of current time
-t STAMP               use [[CC]YY]MMDDhhmm[.ss] instead of current time
--time=WORD        change the specified time:
    WORD is access, atime, or use: equivalent to -a
    WORD is modify or mtime: equivalent to -m
--help      显示此帮助信息并退出
--version     显示版本信息并退出
</code></pre><h3 id="惊"><a href="#惊" class="headerlink" title="惊!"></a>惊!</h3><p>touch是可以指定最后修改时间的!也就是说,<code>touch --date=&quot;2017-05-25 12:00:00&quot; reload&quot;</code>,这个命令可以将reload的最后修改时间改回去!<br>人与人之间最基本的信任呢.</p>
<h3 id="Stat"><a href="#Stat" class="headerlink" title="Stat"></a>Stat</h3><p>放心,<code>stat reload</code>这个命令还是可以看出问题来的.</p>
<pre><code>文件：&quot;reload&quot;
大小：0             块：0          IO 块：4096   普通空文件
    设备：808h/2056d    Inode：25039211    硬链接：1
权限：(0664/-rw-rw-r--)  Uid：( 1000/ catchen)   Gid：( 1000/ catchen)
    最近访问：2017-05-25 12:00:00.000000000 +0800
    最近更改：2017-05-25 12:00:00.000000000 +0800
    最近改动：2017-05-26 15:38:02.693909554 +0800
    创建时间：-
</code></pre><h3 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h3><p>这感觉,就像ls无法告诉我真实大小一样,现在连最后修改时间都不行了.</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="Touch"><a href="#Touch" class="headerlink" title="Touch"></a>Touch</h3><p>touch这个命令,对于一个技术而言,应该是十分熟悉的.<br>像uwsgi这种就可以使用监听一个文件的方式来触发服]]>
    </summary>
    
      <category term="学习" scheme="http://catlittlechen.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="学习" scheme="http://catlittlechen.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[dmesg]]></title>
    <link href="http://catlittlechen.com/2017/04/06/dmesg/"/>
    <id>http://catlittlechen.com/2017/04/06/dmesg/</id>
    <published>2017-04-06T12:09:19.000Z</published>
    <updated>2017-04-08T08:26:00.000Z</updated>
    <content type="html"><![CDATA[<h2 id="用处"><a href="#用处" class="headerlink" title="用处"></a>用处</h2><p>dmesg显示内核环缓冲区内容，一般我都是来查看比如oom之类的问题。之前我同事问我时间怎么算。我也是一直没记录这个公式，只放在印象笔记里面，现在就写在这里吧。</p>
<h2 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h2><p>dmesg的时间确实难看懂，可以通过以下的命令转化<br><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">date</span> -d <span class="string">"1970-01-01 UTC `echo "</span>$(<span class="keyword">date</span> +%s)-$(cat /<span class="keyword">proc</span>/uptime|cut -f <span class="number">1</span> -d<span class="string">' '</span>)+dmesg的时间戳<span class="string">"|bc ` seconds"</span></span><br></pre></td></tr></table></figure></p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="用处"><a href="#用处" class="headerlink" title="用处"></a>用处</h2><p>dmesg显示内核环缓冲区内容，一般我都是来查看比如oom之类的问题。之前我同事问我时间怎么算。我也是一直没记录这个公式，只放在印象笔记里面]]>
    </summary>
    
      <category term="学习" scheme="http://catlittlechen.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="学习" scheme="http://catlittlechen.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[pyrobuf]]></title>
    <link href="http://catlittlechen.com/2017/04/02/pyrobuf/"/>
    <id>http://catlittlechen.com/2017/04/02/pyrobuf/</id>
    <published>2017-04-02T14:03:44.000Z</published>
    <updated>2017-04-02T14:30:07.000Z</updated>
    <content type="html"><![CDATA[<h2 id="protobuf"><a href="#protobuf" class="headerlink" title="protobuf"></a>protobuf</h2><p>Protocol Buffers 是一种轻便高效的结构化数据存储格式。我也是重度使用者。最近需要大量的实时处理Tb级别的数据，因此找到了protobuf的代替库 —- <a href="https://github.com/appnexus/pyrobuf" target="_blank" rel="noopener">pyrobuf</a></p>
<h2 id="pyrobuf"><a href="#pyrobuf" class="headerlink" title="pyrobuf"></a>pyrobuf</h2><p>pyrobuf是一个使用cython的pb库。一开始从他的github中，我确实看到了挺好的优化效果。</p>
<p>但是pyrobuf这个库的限制还是蛮大的，主要是对于proto文件。比如</p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>. 不能在message里面定义数据结构，不然转化的过程中，会找不到定义；</span><br><span class="line"><span class="number">2</span>. proto定义的过程中，message的定义不能加上分号为结尾；</span><br><span class="line"><span class="number">3</span>. <span class="class"><span class="keyword">enum</span>定义的类型，生成之后暂时还找不到映射会名称的方式；</span></span><br></pre></td></tr></table></figure>
<h2 id="use"><a href="#use" class="headerlink" title="use"></a>use</h2><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install </span>pyrobuf</span><br><span class="line">pyrobuf --out-<span class="keyword">dir </span>out --<span class="keyword">build-dir </span><span class="keyword">build </span>--<span class="keyword">install</span></span><br></pre></td></tr></table></figure>
<p>这里面，out目录存放着生成的cython的代码，build目录存放这边一好的so文件，而install的参数添加之后，则pyrobuf会将编译好的so文件复制到python的library目录，这就可以直接使用。</p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>上线观察了下数据，原本20分钟转化的数据，只用了4分钟就转化完毕。不过数据内容还没有核对，晚点再查看吧~</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="protobuf"><a href="#protobuf" class="headerlink" title="protobuf"></a>protobuf</h2><p>Protocol Buffers 是一种轻便高效的结构化数据存储格式。我也是重度使用者。最近]]>
    </summary>
    
      <category term="python" scheme="http://catlittlechen.com/tags/python/"/>
    
      <category term="pyrobuf" scheme="http://catlittlechen.com/tags/pyrobuf/"/>
    
      <category term="python" scheme="http://catlittlechen.com/categories/python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[那些年不懂的spark(2)]]></title>
    <link href="http://catlittlechen.com/2017/03/30/%E9%82%A3%E4%BA%9B%E5%B9%B4%E4%B8%8D%E6%87%82%E7%9A%84spark-2/"/>
    <id>http://catlittlechen.com/2017/03/30/那些年不懂的spark-2/</id>
    <published>2017-03-30T11:38:28.000Z</published>
    <updated>2017-04-02T14:01:47.000Z</updated>
    <content type="html"><![CDATA[<h2 id="partitionBy-amp-amp-s3"><a href="#partitionBy-amp-amp-s3" class="headerlink" title="partitionBy &amp;&amp; s3"></a>partitionBy &amp;&amp; s3</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df<span class="selector-class">.write</span><span class="selector-class">.partitionBy</span>(<span class="string">'date'</span>, <span class="string">'index1'</span>, <span class="string">'index2'</span>, <span class="string">'index3'</span>).parquet(<span class="string">'some/path/'</span>)</span><br></pre></td></tr></table></figure>
<p>我用spark程序在输出parquet的过程中，通过partitionBy的column来自动生成文件夹。由于spark在写入的过程中，会扫描<code>some/path/</code>的所有目录。然后由于我的目录中有以<code>date</code>这个时间维度的标准的，这造成随着时间的推移，文件夹会越来越多，扫描的数据也就越来越慢。然后由于我使用的存储是s3，而s3不是一个真正意义上的文件系统，因而扫描文件夹的过程是一个调用api的过程，就更加慢了~</p>
<p>解决方式：可以写入hdfs等文件系统，再通过s3-dist-cp这个工具同步到s3上。</p>
<h2 id="so文件"><a href="#so文件" class="headerlink" title="so文件"></a>so文件</h2><p>spark 可以通过sparkContext.addFiles这个api，把so文件添加到任务实例上。</p>
<h2 id="结局"><a href="#结局" class="headerlink" title="结局"></a>结局</h2><p>未完待续</p>
<h2 id="Done"><a href="#Done" class="headerlink" title="Done"></a>Done</h2>]]></content>
    <summary type="html">
    <![CDATA[<h2 id="partitionBy-amp-amp-s3"><a href="#partitionBy-amp-amp-s3" class="headerlink" title="partitionBy &amp;&amp; s3"></a>partitionBy &amp;]]>
    </summary>
    
      <category term="踩坑日记" scheme="http://catlittlechen.com/tags/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/"/>
    
      <category term="spark" scheme="http://catlittlechen.com/tags/spark/"/>
    
      <category term="spark" scheme="http://catlittlechen.com/categories/spark/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[那些年不懂的spark]]></title>
    <link href="http://catlittlechen.com/2017/03/19/%E9%82%A3%E4%BA%9B%E5%B9%B4%E4%B8%8D%E6%87%82%E7%9A%84spark/"/>
    <id>http://catlittlechen.com/2017/03/19/那些年不懂的spark/</id>
    <published>2017-03-19T02:31:34.000Z</published>
    <updated>2017-03-26T01:30:34.000Z</updated>
    <content type="html"><![CDATA[<h2 id="感悟"><a href="#感悟" class="headerlink" title="感悟"></a>感悟</h2><p>spark是一个好东西。流式处理数据，扩容方便，较大程度上的利用机器，学习还是很有必要的。这几个星期的使用，也踩了不少坑。世界上的很多东西，不是难，而是不知道。</p>
<h2 id="jsc"><a href="#jsc" class="headerlink" title="_jsc"></a>_jsc</h2><p>我是python的使用者，近来发现需要在启动spark的时候设置参数，但是在文档查找的过程中，只发现只有java的api文档里面有相关的参数设置，而python没有。囧~</p>
<p>最后发现python的<code>SparkContext</code>里，有一个参数是<code>_jsc</code>,其代表的恰恰就是java里面的 <code>SparkContext</code>。运行时可以通过这个对象，来实现参数的设置。</p>
<h2 id="parquet-enable-summary-metadata"><a href="#parquet-enable-summary-metadata" class="headerlink" title="parquet.enable.summary-metadata"></a>parquet.enable.summary-metadata</h2><p>上面提到的参数设置，其实就是这个参数了。由于我所使用的spark的版本是1.6.1，因此这个参数默认的值是true，2.0以后默认为false。详细可见 <a href="https://issues.apache.org/jira/browse/SPARK-15719" target="_blank" rel="noopener">issue</a></p>
<p>大概意思如下，spark在生成parquet文件的过程中，最后会扫描文件夹下的所有文件，并将文件的大致的详细汇总到文件夹目录的metadata文件，完成这个过程之后，在下次直接匹配这个文件夹的时候，spark会读取metadata，加快扫描的速度。</p>
<p>问题是生成这个metadata的文件是需要扫描所有文件的！而我生成paruqet的时候，是以追加的形式加入，频率还是蛮高的情况下，这就意味着我的spark程序会花费大量的时间在汇总这部分数据。并且汇总数据的过程是不会分布到多台机器上运行的。这就大大的降低了集群的利用率，其实也毫无必要。</p>
<p>因此spark生成parquet的过程中，可以选择关闭这个特性~</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sparkContext._jsc<span class="selector-class">.hadoopConfiguration</span><span class="selector-class">.set</span>(<span class="string">'parquet.enable.summary-metadata'</span>, <span class="string">'false'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="partitionBy"><a href="#partitionBy" class="headerlink" title="partitionBy"></a>partitionBy</h2><p>一开始我一直纠结了很多问题，output的分类就是其中一个。而<code>partitonBy</code>完美地解决了我的需求。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df<span class="selector-class">.write</span><span class="selector-class">.partitionBy</span>(<span class="string">'index1'</span>, <span class="string">'index2'</span>, <span class="string">'index3'</span>).parquet(<span class="string">'some/path/'</span>)</span><br></pre></td></tr></table></figure>
<p>以上的代码中，<code>df</code>为一个dataFrame的数据集。</p>
<p>这段代码可以根据index1, index2, index3这几个columns来分类，将数据自动分为如下的目录结构保存.</p>
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">some/path/i<span class="symbol">ndex1</span>=&#123;i<span class="symbol">ndex1</span>&#125;/i<span class="symbol">ndex2</span>=&#123;i<span class="symbol">ndex2</span>&#125;/i<span class="symbol">ndex3</span>=&#123;i<span class="symbol">ndex3</span>&#125;/part-****.parquet</span><br></pre></td></tr></table></figure>
<p>之前还傻乎乎地groupBy数据，然后用了collect这个算子，因而需要读取所有文件，就有内存问题等存在。</p>
<h2 id="binaryFiles"><a href="#binaryFiles" class="headerlink" title="binaryFiles"></a>binaryFiles</h2><p>这个不算坑，只是自己没有注意到而已。</p>
<p>之前都是使用<code>textFile</code>的格式读取文本文件，这个过程中，没有指定<code>minPartition</code>，而<code>minPartition</code>的值也基本默认为文本文件的个数。但是<code>binaryFiles</code>不是。程序在默认读取大量二进制文件之后，并没有选择分开，而是<code>minPartition</code>为1，因此这里需要手动指定。</p>
<h2 id="parquet-amp-amp-sparkSQL"><a href="#parquet-amp-amp-sparkSQL" class="headerlink" title="parquet &amp;&amp; sparkSQL"></a>parquet &amp;&amp; sparkSQL</h2><p>sparkSQL太杀手级了~</p>
<p>parquet是列存储数据模式，可以大大的减少存储的文件大小，减少扫描过程中的大小。效率惊人~</p>
<p>sparkSQL在读取文件夹目录下所有文件的过程中，存在一个特定<code>partition auto-discovery</code>的特性。在spark的文档中有详细的记载。大概如下：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = sqlContext<span class="selector-class">.read</span><span class="selector-class">.parquet</span>(/some/path)</span><br></pre></td></tr></table></figure>
<p>如果<code>/some/path</code>下有目录如下<br><figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/some/path</span></span><br><span class="line">	-<span class="ruby">- <span class="regexp">/index1=h1/index</span>2=f1/</span></span><br><span class="line"><span class="ruby">	-- <span class="regexp">/index1=h1/index</span>2=f2/</span></span><br><span class="line"><span class="ruby">	-- <span class="regexp">/index1=h2/index</span>2=f1/</span></span><br><span class="line"><span class="ruby">	-- <span class="regexp">/index1=h2/index</span>2=f2/</span></span><br></pre></td></tr></table></figure></p>
<p>则最后生成的sparkSQL的table里面，将会自动的加入index1, index2的column，当你使用index1来查询时，即</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">df</span><span class="selector-class">.registerTempTable</span>(<span class="string">"log"</span>)</span><br><span class="line"><span class="selector-tag">sqlContext</span><span class="selector-class">.sql</span>(<span class="string">"SELECT * FROM log WHERE index1 = h1"</span>)</span><br></pre></td></tr></table></figure>
<p>这个过程中，会自动的只扫描index1=h1的目录下的文件。<br>缺点是我喜欢使用通配符的形式来读取，结果通配的列就不存在了~<br>sad~</p>
<h2 id="结局"><a href="#结局" class="headerlink" title="结局"></a>结局</h2><p>未完待续~</p>
<h2 id="Done"><a href="#Done" class="headerlink" title="Done"></a>Done</h2>]]></content>
    <summary type="html">
    <![CDATA[<h2 id="感悟"><a href="#感悟" class="headerlink" title="感悟"></a>感悟</h2><p>spark是一个好东西。流式处理数据，扩容方便，较大程度上的利用机器，学习还是很有必要的。这几个星期的使用，也踩了不少坑。世界上的很多东西，]]>
    </summary>
    
      <category term="踩坑日记" scheme="http://catlittlechen.com/tags/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/"/>
    
      <category term="spark" scheme="http://catlittlechen.com/tags/spark/"/>
    
      <category term="spark" scheme="http://catlittlechen.com/categories/spark/"/>
    
  </entry>
  
</feed>
